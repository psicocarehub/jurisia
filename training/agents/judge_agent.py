"""
Judge Profile Agent: enriches responses with real tribunal patterns.

Loads tribunal_patterns.json (generated by collect_stj_scenarios.py
and update_tribunal_patterns DAG) and provides contextual information
about how courts actually decide on the given topic.
"""

import json
from pathlib import Path
from typing import Any

from training.agents.state import DebateState

PATTERNS_PATHS = [
    "training/data/tribunal_patterns.json",
    "/opt/airflow/data/tribunal_patterns.json",
]


def _load_patterns() -> dict[str, Any]:
    """Load tribunal patterns from file."""
    for path in PATTERNS_PATHS:
        p = Path(path)
        if p.exists():
            return json.loads(p.read_text(encoding="utf-8"))
    return {"tribunals": {}}


def _find_relevant_sumulas(
    patterns: dict[str, Any],
    area: str,
    text: str,
) -> list[str]:
    """Find sumulas relevant to the area and question."""
    relevant: list[str] = []

    for tribunal_name, tribunal_data in patterns.get("tribunals", {}).items():
        sumula_data = tribunal_data.get("patterns", {}).get("sumula_citations", {})
        top = sumula_data.get("top_sumulas", [])
        for entry in top[:10]:
            relevant.append(f"{entry['sumula']} (citada {entry['count']}x)")

    return relevant[:15]


def _find_relevant_teses(
    patterns: dict[str, Any],
    area: str,
) -> list[str]:
    """Find binding theses relevant to the area."""
    teses: list[str] = []

    for tribunal_name, tribunal_data in patterns.get("tribunals", {}).items():
        pattern_data = tribunal_data.get("patterns", {})
        firmadas = pattern_data.get("teses_firmadas", [])
        for tese in firmadas[:10]:
            teses.append(f"[{tribunal_name}] {tese}")

    return teses[:10]


def _get_area_stats(
    patterns: dict[str, Any],
    area: str,
) -> dict[str, Any]:
    """Get area-specific statistics from tribunal data."""
    stats: dict[str, Any] = {}

    for tribunal_name, tribunal_data in patterns.get("tribunals", {}).items():
        pattern_data = tribunal_data.get("patterns", {})

        area_dist = pattern_data.get("area_distribution", {})
        if area in area_dist:
            stats[f"{tribunal_name}_count"] = area_dist[area]

        articles = pattern_data.get("article_citations", {}).get("top_articles", [])
        stats[f"{tribunal_name}_top_articles"] = [
            a["article"] for a in articles[:5]
        ]

    return stats


async def judge_node(state: DebateState) -> dict:
    """Enrich the response with real tribunal patterns."""
    patterns = _load_patterns()
    area = state.get("area", "geral")
    question = state.get("question", "")

    context_parts: list[str] = []

    sumulas = _find_relevant_sumulas(patterns, area, question)
    if sumulas:
        context_parts.append("SÚMULAS MAIS CITADAS PELO TRIBUNAL:")
        for s in sumulas:
            context_parts.append(f"  - {s}")

    teses = _find_relevant_teses(patterns, area)
    if teses:
        context_parts.append("\nTESES FIRMADAS EM REPETITIVOS:")
        for t in teses:
            context_parts.append(f"  - {t}")

    stats = _get_area_stats(patterns, area)
    if stats:
        context_parts.append(f"\nESTATÍSTICAS DA ÁREA '{area}':")
        for key, val in stats.items():
            if isinstance(val, list):
                context_parts.append(f"  {key}: {', '.join(val)}")
            else:
                context_parts.append(f"  {key}: {val}")

    favorability = patterns.get("tribunals", {}).get("STJ", {}).get("patterns", {}).get("favorability", {})
    if favorability:
        context_parts.append(f"\nDADOS DE FAVORABILIDADE STJ: {json.dumps(favorability, ensure_ascii=False)[:500]}")

    if not context_parts:
        context_parts.append("Nenhum pattern de tribunal disponível para esta área.")

    tribunal_context = "\n".join(context_parts)

    return {
        "tribunal_context": tribunal_context,
        "tribunal_patterns": {
            "sumulas_found": len(sumulas),
            "teses_found": len(teses),
            "area": area,
        },
    }
